#!/usr/bin/env python
# coding: utf-8

# In[47]:


import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score


# In[48]:


train_df = pd.read_csv('/Users/steve/Documents/projects/microsoft_malware_data/train.csv',low_memory=False, nrows=2000)


# In[68]:


holdout_df = pd.read_csv('/Users/steve/Documents/projects/microsoft_malware_data/test.csv',low_memory=False)


# In[50]:


def process(df):
    #capturing ids
    ids = df.MachineIdentifier
    
    #removing object (categorical) columns that have all unique values
    drop_cols = df.columns[df.describe(include='all').loc['count']==df.describe(include='all').loc['unique']]
    df = df.drop(columns=drop_cols)

    #removing columns with > 30% null values
    thresh = df.shape[0]*.7
    df = df.dropna(thresh=thresh, axis=1)

    #removing records that have null values
    df = df.dropna(axis=0)

    #removing features with 1 unique value
    cols = df.columns[df.describe(include='all').loc['unique'] == 1]
    df = df.drop(columns=cols)

    #removing numerical features that are all zero
    cols = df.select_dtypes(include=np.number).columns[(df.describe().loc['min'] == 0) & (df.describe().loc['max'] == 0)]
    df = df.drop(columns=cols)

    #dropping numerical columns with tainted data
    num_cols_to_drop = ['Census_InternalBatteryNumberOfCharges']
    df = df.drop(columns=num_cols_to_drop)

    #one hot encoding numerical features that are in fact categorical
    num_cols_to_cat = ['AVProductStatesIdentifier','CountryIdentifier','CityIdentifier','GeoNameIdentifier','LocaleEnglishNameIdentifier','OsSuite','IeVerIdentifier','Census_OEMNameIdentifier','Census_OEMModelIdentifier','Census_ProcessorManufacturerIdentifier','Census_ProcessorModelIdentifier','Census_OSInstallLanguageIdentifier','Census_OSUILocaleIdentifier','Census_FirmwareManufacturerIdentifier','Census_FirmwareVersionIdentifier','Wdft_RegionIdentifier']
    df = pd.get_dummies(df, columns=num_cols_to_cat)

    #one hot encoding true categorical features
    df = pd.get_dummies(df)

    #normalize non dummy / non categorical columns
    cols = df.select_dtypes(exclude=['uint8','category']).columns
    df[cols] = (df[cols] - df[cols].min())/(df[cols].max() - df[cols].min())    
    
    df['MachineIdentifier'] = ids
    
    return df


# In[51]:


def rank_features(df):
    df = df.drop(columns='MachineIdentifier')
    corrs = df.corr().HasDetections
    ranked_features = corrs.abs().sort_values(ascending=False)[1:]
    return ranked_features


# In[52]:


def fit_to_train(df, ranked_features, top_n_feats):
    model = LogisticRegression()
    cols = ranked_features.index[:top_n_feats]
    X = df[cols]
    y = df.HasDetections
    model.fit(X, y)
    return model


# In[61]:


def predict_holdout(df, model, ranked_features, top_n_feats):
    cols = ranked_features.index[:top_n_feats]
    X = df[cols]
    preds = model.predict(X)
    df = pd.DataFrame({'MachineIdentifier':df.MachineIdentifier, 'HasDetections':preds})
    return df


# In[64]:


def create_submissin_file(df, filename='submission.csv'):
    df.to_csv(filename, index=False)


# In[54]:


train_df_processed = process(train_df)


# In[ ]:


holdout_df_processed = process(holdout_df)


# In[56]:


ranked_features = rank_features(train_df_processed)


# In[57]:


fit_model = fit_to_train(train_df_processed, ranked_features, 412)


# In[63]:


prediction_df = predict_holdout(train_df_processed, fit_model, ranked_features, 412)


# In[67]:


create_submissin_file(prediction_df)


# In[ ]:





# def pipeline(df, top_n):
# #pre processing
#     
#     #capturing ids
#     ids = df.MachineIdentifier
#     
#     #removing object (categorical) columns that have all unique values
#     drop_cols = df.columns[df.describe(include='all').loc['count']==df.describe(include='all').loc['unique']]
#     df = df.drop(columns=drop_cols)
# 
#     #removing columns with > 30% null values
#     thresh = df.shape[0]*.7
#     df = df.dropna(thresh=thresh, axis=1)
# 
#     #removing records that have null values
#     df = df.dropna(axis=0)
# 
#     #removing features with 1 unique value
#     cols = df.columns[df.describe(include='all').loc['unique'] == 1]
#     df = df.drop(columns=cols)
# 
#     #removing numerical features that are all zero
#     cols = df.select_dtypes(include=np.number).columns[(df.describe().loc['min'] == 0) & (df.describe().loc['max'] == 0)]
#     df = df.drop(columns=cols)
# 
#     #dropping numerical columns with tainted data
#     num_cols_to_drop = ['Census_InternalBatteryNumberOfCharges']
#     df = df.drop(columns=num_cols_to_drop)
# 
#     #one hot encoding numerical features that are in fact categorical
#     num_cols_to_cat = ['AVProductStatesIdentifier','CountryIdentifier','CityIdentifier','GeoNameIdentifier','LocaleEnglishNameIdentifier','OsSuite','IeVerIdentifier','Census_OEMNameIdentifier','Census_OEMModelIdentifier','Census_ProcessorManufacturerIdentifier','Census_ProcessorModelIdentifier','Census_OSInstallLanguageIdentifier','Census_OSUILocaleIdentifier','Census_FirmwareManufacturerIdentifier','Census_FirmwareVersionIdentifier','Wdft_RegionIdentifier']
#     df = pd.get_dummies(df, columns=num_cols_to_cat)
# 
#     #one hot encoding true categorical features
#     df = pd.get_dummies(df)
# 
#     #normalize non dummy / non categorical columns
#     cols = df.select_dtypes(exclude=['uint8','category']).columns
#     df[cols] = (df[cols] - df[cols].min())/(df[cols].max() - df[cols].min())    
#     
#     df['MachineIdentifier'] = ids
#     
# #prioritizing features
#     corrs = df.corr().HasDetections
#     ranked_corrs = corrs.abs().sort_values(ascending=False)[1:]
# 
# #training
#     model = LogisticRegression()
#     cols = ranked_corrs.index[:top_n]
#     X = df[cols]
#     y = df.HasDetections
#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=4)
#     model.fit(X_train, y_train)
#     preds = model.predict(X_test)
# 
# #submission
# #process submission features
#     

# pipeline(df, 412)

# In[ ]:




